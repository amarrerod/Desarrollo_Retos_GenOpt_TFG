@article{obl,
abstract = {Opposition-based learning as a new scheme for machine intelligence is introduced. Estimates and counter-estimates, weights and opposite weights, and actions versus counter-actions are the foundation of this new approach. Examples are provided. Possibilities for extensions of existing learning algorithms are discussed. Preliminary results are provided},
author = {Tizhoosh, H R},
doi = {10.1109/CIMCA.2005.1631345},
file = {:C$\backslash$:/Users/Alejandro/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tizhoosh - 2005 - Opposition-Based Learning A New Scheme for Machine Intelligence.pdf:pdf},
isbn = {0-7695-2504-0},
journal = {Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, International Conference on},
keywords = {estimation theory,learning (artificial intelligence),machine intelligence,opposition-based learning,optimisation,search problems},
pages = {695--701},
title = {{Opposition-Based Learning: A New Scheme for Machine Intelligence}},
volume = {1},
year = {2005}
}


@book{metaheuristics,
place={Hoboken},
edition={1},
title={Metaheuristics},
publisher={Wiley},
author={Talbi, El-Ghazali},
year={2009}
}

@Article{Segredo2017,
author="Segredo, Eduardo
and Paechter, Ben
and Segura, Carlos
and Gonz{\'a}lez-Vila, Carlos I.",
title="On the comparison of initialisation strategies in differential evolution for large scale optimisation",
journal="Optimization Letters",
year="2017",
pages="1--14",
abstract="Differential Evolution (de) has shown to be a promising global optimisation solver for continuous problems, even for those with a large dimensionality. Different previous works have studied the effects that a population initialisation strategy has on the performance of de when solving large scale continuous problems, and several contradictions have appeared with respect to the benefits that a particular initialisation scheme might provide. Some works have claimed that by applying a particular approach to a given problem, the performance of de is going to be better than using others. In other cases however, researchers have stated that the overall performance of de is not going to be affected by the use of a particular initialisation method. In this work, we study a wide range of well-known initialisation techniques for de. Taking into account the best and worst results, statistically significant differences among considered initialisation strategies appeared. Thus, with the aim of increasing the probability of appearance of high-quality results and/or reducing the probability of appearance of low-quality ones, a suitable initialisation strategy, which depends on the large scale problem being solved, should be selected.",
issn="1862-4480",
}

@ARTICLE{GRASP,
author={Díaz, J.A. and Luna, D.E. and Camacho-Vallejo, J.-F. and Casas-Ramírez, M.-S.},
title={GRASP and hybrid GRASP-Tabu heuristics to solve a maximal covering location problem with customer preference ordering},
journal={Expert Systems with Applications},
year={2017},
volume={82},
pages={67-76},
note={cited By 0},
document_type={Article},
source={Scopus},
}
@ARTICLE{SA,
author={Gerber, M. and Bornn, L.},
title={Improving simulated annealing through derandomization},
journal={Journal of Global Optimization},
year={2017},
volume={68},
number={1},
pages={189-217},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE1,
author={Zheng, L.M. and Zhang, S.X. and Tang, K.S. and Zheng, S.Y.},
title={Differential evolution powered by collective information},
journal={Information Sciences},
year={2017},
volume={399},
pages={13-29},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE2,
author={Fu, C.M. and Jiang, C. and Chen, G.S. and Liu, Q.M.},
title={An adaptive differential evolution algorithm with an aging leader and challengers mechanism},
journal={Applied Soft Computing Journal},
year={2017},
volume={57},
pages={60-73},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@ARTICLE{DE3,
author={Tian, M. and Gao, X. and Dai, C.},
title={Differential evolution with improved individual-based parameter setting and selection strategy},
journal={Applied Soft Computing Journal},
year={2017},
volume={56},
pages={286-297},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@CONFERENCE{CMA,
author={Hajebi, M. and Hoorfar, A. and Bou-Daher, E.},
title={Inverse profiling of inhomogenous buried cylinders with arbitrary cross sections using CMA-ES},
journal={2016 IEEE Antennas and Propagation Society International Symposium, APSURSI 2016 - Proceedings},
year={2016},
pages={863-864},
art_number={7696140},
note={cited By 0},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{COE1,
author={Atashpendar, A. and Dorronsoro, B. and Danoy, G. and Bouvry, P.},
title={A parallel cooperative coevolutionary SMPSO algorithm for multi-objective optimization},
journal={2016 International Conference on High Performance Computing and Simulation, HPCS 2016},
year={2016},
pages={713-720},
art_number={7568405},
note={cited By 0},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{COE2,
author={Hajikolaei, K.H. and Cheng, G.H. and Wang, G.G.},
title={Optimization on Metamodeling-Supported Iterative Decomposition},
journal={Journal of Mechanical Design, Transactions of the ASME},
year={2016},
volume={138},
number={2},
art_number={021401},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@CONFERENCE{COE3,
author={Glorieux, E. and Svensson, B. and Danielsson, F. and Lennartson, B.},
title={Improved constructive cooperative coevolutionary differential evolution for large-scale optimisation},
journal={Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015},
year={2016},
pages={1703-1710},
art_number={7376815},
note={cited By 0},
document_type={Conference Paper},
source={Scopus},
}

@article{OPSO,
abstract = {Particle Swarm Optimization, a population based optimization technique has been used in wide number of application areas to solve optimization problems. This paper presents a new algorithm for initialization of population in standard PSO called Opposition based Particle Swarm Optimization (O-PSO). The performance of proposed initialization algorithm is compared with the existing PSO variants on several benchmark functions and the experimental results reveal that O-PSO outperforms existing approaches to a large extent.},
author = {Jabeen, Hajira and Jalil, Zunera and Baig, Abdul Rauf},
isbn = {9781605585055},
journal = {Proceedings of the 11th annual conference companion on Genetic and evolutionary computation conference - GECCO '09},
keywords = {initialization,opposition based learning,optimization,pso,swarm intelligence},
pages = {2047},
title = {{Opposition based initialization in particle swarm optimization (O-PSO)}},
year = {2009}
}

@article{OPSO2,
abstract = {Particle swarm optimization (PSO) is a stochastic, population-based optimization method, which has been applied successfully to a wide range of problems. However, PSO is computationally expensive and suffers from premature convergence. In this paper, opposition-based learning is used to improve the performance of PSO. The performance of the proposed approaches is investigated and compared with PSO when applied to eight benchmark functions. The experiments conducted show that opposition-based learning improves the performance of PSO.},
author = {Omran, Mahamed G. H. and Al-Sharhan, Salah},
isbn = {978-1-4244-2704-8},
journal = {2008 IEEE Swarm Intelligence Symposium},
number = {1},
pages = {1--6},
title = {{Using opposition-based learning to improve the performance of particle swarm optimization}},
year = {2008}
}

@article{obl2,
abstract = {Evolutionary algorithms (EAs) are well-known optimization approaches to deal with nonlinear and complex problems. However, these population-based algorithms are computationally expensive due to the slow nature of the evolutionary process. This paper presents a novel algorithm to accelerate the differential evolution (DE). The proposed opposition-based DE (ODE) employs opposition-based learning (OBL) for population initialization and also for generation jumping. In this work, opposite numbers have been utilized to improve the convergence rate of DE. A comprehensive set of 58 complex benchmark functions including a wide range of dimensions is employed for experimental verification. The influence of dimensionality, population size, jumping rate, and various mutation strategies are also investigated. Additionally, the contribution of opposite numbers is empirically verified. We also provide a comparison of ODE to fuzzy adaptive DE (FADE). Experimental results confirm that the ODE outperforms the original DE and FADE in terms of convergence speed and solution accuracy.},
author = {Rahnamayan, Shahryar and Tizhoosh, Hamid R. and Salama, Magdy M.},
isbn = {9783540688273},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
number = {1},
pages = {155--171},
title = {{Opposition-based differential evolution}},
volume = {143},
year = {2008}
}

@article{comparison,
abstract = {This paper focuses on the three very similar evolutionary algorithms,$\backslash$nGenetic Algorithm (GA), Particle Swarm Optimization (PSO), and Differential$\backslash$nEvolution (DE). While GA is more suitable for discrete optimization,$\backslash$nPSO and DE are more natural for continuous optimization. The paper$\backslash$nfirst gives a brief introduction to the three EA techniques to highlight$\backslash$nthe common computational procedures. The general observations on$\backslash$nthe similarities and differences among the three algorithms based$\backslash$non computational steps are discussed. Contrasts are given on some$\backslash$nbasic observations on performances of algorithms. Summary of relevant$\backslash$nliteratures on job shop, flexible job shop, vehicle routing, location-allocation,$\backslash$nand multimode resource constrained project scheduling problems are$\backslash$ngiven.},
author = {Kachitvichyanukul, Voratas},
issn = {1598-7248},
journal = {Industrial Engineering and Management Systems},
keywords = {ac,ait,corresponding author,differential evolution,e-mail,evolutionary algorithm,genetic algorithm,particle swarm optimization,th,voratas},
number = {3},
pages = {215--223},
title = {{GA/PSO/DE..Comparison of Three Evolutionary Algorithms: GA, PSO, and DE}},
volume = {11},
year = {2012}
}
@article{GPSO,
author = {Pasupuleti, Srinivas and Battiti, Roberto},
isbn = {1595931864},
journal = {Proceedings of the 8th annual conference on Genetic and evolutionary computation - GECCO '06},
keywords = {differ-,particle swarm algorithm,repeated affine shaker},
number = {0},
pages = {67},
title = {{The gregarious particle swarm optimizer (G-PSO)}},
volume = {1},
year = {2006}
}
@article{OPSO3,
abstract = {Particle Swarm Optimization, a population based optimization technique has been used in wide number of application areas to solve optimization problems. This paper presents a new algorithm for initialization of population in standard PSO called Opposition based Particle Swarm Optimization (O-PSO). The performance of proposed initialization algorithm is compared with the existing PSO variants on several benchmark functions and the experimental results reveal that O-PSO outperforms existing approaches to a large extent.},
author = {Jabeen, Hajira and Jalil, Zunera and Baig, Abdul Rauf},
isbn = {9781605585055},
journal = {Proceedings of the 11th annual conference companion on Genetic and evolutionary computation conference - GECCO '09},
keywords = {initialization,opposition based learning,optimization,pso,swarm intelligence},
pages = {2047},
title = {{Opposition based initialization in particle swarm optimization (O-PSO)}},
year = {2009}
}

@article{PSO_KA,
abstract = {— A new technique titled " Particle Refresh " and a hybridization with conjugate gradient method are introduced to particle swarm optimization (PSO). The former charges power to inactive particle to improve the recovery ability of PSO after trapping on a local solution, and as a result, it becomes easy to choose suitable values for control-parameters to keep high performance for diverse objective functions. On the other hand, the point of the latter is how to determine the changeover timing between a conjugate gradient method and a PSO algorithm.},
author = {Kawakami, K. and Meng, Zhi Qi},
issn = {1931-7360},
journal = {PIERS Online},
keywords = {-component,chain mnagement,ga,genetic algorithm,mutation,particle swarm optimization,pso,sa,scm,stability analysis,supply},
number = {2},
pages = {261--264},
title = {{Improvement of Particle Swarm Optimization}},
volume = {5},
year = {2009}
}

@book{metabook,
author = {Du, Ke-Lin and Swamy, M. N. S.},
isbn = {978-3-319-41191-0},
issn = {3319411926},
pages = {327--336},
title = {{Search and Optimization by Metaheuristics}},
year = {2016}
}

@book{Eiben,
author = {A.E. Eiben, J.E. Smith},
isbn = {9783662448748},
pages = {327--336},
title = {{Introduction to Evolutionary Computing}},
year = {2015}
}

@article{oblcpso,
author = {Zhou, Jianhong and Fang, Wei and Wu, Xiaojun and Sun, Jun and Cheng, Shi},
isbn = {9781509006236},
pages = {515--521},
title = {{An Opposition-Based Learning Competitive Particle Swarm Optimizer}},
year = {2016}
}

@INPROCEEDINGS{GlobalSearch, 
author={Jun Sun and Wenbo Xu and Bin Feng}, 
booktitle={IEEE Conference on Cybernetics and Intelligent Systems, 2004.}, 
title={A global search strategy of quantum-behaved particle swarm optimization}, 
year={2004}, 
volume={1}, 
pages={111-116 vol.1}, 
keywords={evolutionary computation;learning (artificial intelligence);quantum theory;search problems;QPSO algorithm;benchmark functions;learning inclination point;population mainstream thought;quantum-behaved particle swarm optimization algorithm;search strategy;Equations;Genetic algorithms;Information technology;Linear systems;Organisms;Paints;Particle swarm optimization;Quantum mechanics;Sun;Testing}, 
month={Dec},}

@article{GlobalSearch2,
author = {Sigrún Andradóttir},
title = {A Global Search Method for Discrete Stochastic Optimization},
journal = {SIAM Journal on Optimization},
volume = {6},
number = {2},
pages = {513-530},
year = {1996},
}

@Article{GlobalSearch3,
author="Price, W. L.",
title="Global optimization by controlled random search",
journal="Journal of Optimization Theory and Applications",
year="1983",
volume="40",
number="3",
pages="333--348",
abstract="The paper describes a new version, known as CRS2, of the author's controlled random search procedure for global optimization (CRS). The new procedure is simpler and requires less computer storage than the original version, yet it has a comparable performance. The results of comparative trials of the two procedures, using a set of standard test problems, are given. These test problems are examples of unconstrained optimization. The controlled random search procedure can also be effective in the presence of constraints. The technique of constrained optimization using CRS is illustrated by means of examples taken from the field of electrical engineering.",
issn="1573-2878"}

@ARTICLE{SA1,
author={Robini, M.C. and Ozon, M. and Frindel, C. and Yang, F. and Zhu, Y.},
title={Global Diffusion Tractography by Simulated Annealing},
journal={IEEE Transactions on Biomedical Engineering},
year={2017},
volume={64},
number={3},
pages={649-660},
art_number={7473911},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@ARTICLE{SA2,
author={Karagiannis, G. and Konomi, B.A. and Lin, G. and Liang, F.},
title={Parallel and interacting stochastic approximation annealing algorithms for global optimisation},
journal={Statistics and Computing},
year={2017},
volume={27},
number={4},
pages={927-945},
note={cited By 0},
document_type={Article},
source={Scopus},
}

@ARTICLE{SA3,
author={Gerber, M. and Bornn, L.},
title={Improving simulated annealing through derandomization},
journal={Journal of Global Optimization},
year={2017},
volume={68},
number={1},
pages={189-217},
note={cited By 0},
document_type={Article},
source={Scopus},
}
